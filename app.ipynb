{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.cleaning import remove_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lentu la letati nka re thobela</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ka mosa le mogau wa modimo re bone hlabo ya le...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>khadjom thobelafmyaka 015 ka mokopane mesong g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nobodysmakoti2 takatina1 bathandwayo ge go sel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powerfm987 tshegomoagi gabotse taba ya gore le...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0                     lentu la letati nka re thobela   neutral\n",
       "1  ka mosa le mogau wa modimo re bone hlabo ya le...  positive\n",
       "2  khadjom thobelafmyaka 015 ka mokopane mesong g...  negative\n",
       "3  nobodysmakoti2 takatina1 bathandwayo ge go sel...  positive\n",
       "4  powerfm987 tshegomoagi gabotse taba ya gore le...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/100kdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aapoh/codes/ghp/research-assistant/envs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load the MBERT model\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "# Load the corresponding tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Your Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# Prepare a sample text\n",
    "text = [ instance for instance in df['text'].values ]\n",
    "text = text[: 100] # use only 100\n",
    "\n",
    "# # Tokenize the text\n",
    "inputs = tokenizer(text, padding=True, return_tensors='pt')\n",
    "print(inputs.keys())\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 82, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embeddings\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# The last hidden-state is the first element of outputs\n",
    "last_hidden_state = outputs[0]\n",
    "last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get the average of the embeddings to represent the sentence\n",
    "sentence_embedding = last_hidden_state.mean(dim=1)\n",
    "print(sentence_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tuning MBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load a sequence classification version of MBERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "# Suppose we have some training data in two tensors: inputs and labels\n",
    "train_inputs = sentence_embedding # This should be your tensor of input data\n",
    "train_labels = df['label'] # This should be your tensor of labels\n",
    "\n",
    "\n",
    "# Step 1: Create a TrainingArguments object\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",   # Directory where model checkpoints and logs will be saved\n",
    "    num_train_epochs=3,      # Number of training epochs\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=500,          # Save model checkpoints every 500 steps\n",
    "    save_total_limit=2       # Limit the total number of saved checkpoints\n",
    ")\n",
    "\n",
    "# Step 2: Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                 # Your pre-trained model\n",
    "    args=training_args,          # Training arguments\n",
    "    train_dataset=train_inputs   # Training dataset (Dataset object or data collator)\n",
    ")\n",
    "\n",
    "# Step 3: Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
