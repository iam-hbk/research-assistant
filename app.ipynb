{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lentu la letati nka re thobela</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ka mosa le mogau wa modimo re bone hlabo ya le...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>khadjom thobelafmyaka 015 ka mokopane mesong g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nobodysmakoti2 takatina1 bathandwayo ge go sel...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>powerfm987 tshegomoagi gabotse taba ya gore le...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0                     lentu la letati nka re thobela   neutral\n",
       "1  ka mosa le mogau wa modimo re bone hlabo ya le...  positive\n",
       "2  khadjom thobelafmyaka 015 ka mokopane mesong g...  negative\n",
       "3  nobodysmakoti2 takatina1 bathandwayo ge go sel...  positive\n",
       "4  powerfm987 tshegomoagi gabotse taba ya gore le...  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/100kdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertModel, BertTokenizer\n\u001b[0;32m      3\u001b[0m \u001b[39m# Load the MBERT model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-multilingual-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Load the corresponding tokenizer\u001b[39;00m\n\u001b[0;32m      7\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-multilingual-uncased\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\ronny\\research-assistant\\envs\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1039\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1038\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1039\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\ronny\\research-assistant\\envs\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1027\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1025\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m   1026\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m-> 1027\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load the MBERT model\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "# Load the corresponding tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Your Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a sample text\n",
    "text = \"Hello, world!\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Here, 'pt' indicates that we want PyTorch tensors. You can use 'tf' for TensorFlow tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# The last hidden-state is the first element of outputs\n",
    "last_hidden_state = outputs[0]\n",
    "\n",
    "print(last_hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: get the average of the embeddings to represent the sentence\n",
    "sentence_embedding = last_hidden_state.mean(dim=1)\n",
    "print(sentence_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-Tuning MBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load a sequence classification version of MBERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "# Suppose we have some training data in two tensors: inputs and labels\n",
    "train_inputs = ... # This should be your tensor of input data\n",
    "train_labels = ... # This should be your tensor of labels\n",
    "\n",
    "# Set up the trainer\n",
    "training_args = TrainingArguments(output_dir='./results', num_train_epochs=3)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_inputs, labels=train_labels)\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
